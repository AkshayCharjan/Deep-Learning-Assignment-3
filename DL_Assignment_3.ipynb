{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-cN-1QgMzV0"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMo3bJHwIx11",
        "outputId": "aa7197d9-292f-41a3-9c59-03f4d346717f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.0.2-py3-none-any.whl (719 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.0/719.0 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (2.0.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (4.65.0)\n",
            "Collecting lightning-utilities>=0.7.0\n",
            "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (23.1)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (2023.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning) (4.5.0)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.27.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch_lightning) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch_lightning) (3.11.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch_lightning) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch_lightning) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch_lightning) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch_lightning) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch_lightning) (16.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (23.1.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.3/269.3 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.0.12)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.11.0->pytorch_lightning) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.11.0->pytorch_lightning) (1.3.0)\n",
            "Installing collected packages: multidict, lightning-utilities, frozenlist, async-timeout, yarl, aiosignal, aiohttp, torchmetrics, pytorch_lightning\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 lightning-utilities-0.8.0 multidict-6.0.4 pytorch_lightning-2.0.2 torchmetrics-0.11.4 yarl-1.9.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (6.0)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (67.7.1)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.20.0-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.8/198.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.4.4)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=f94c867166727b5b09c222b41dbdaa81444f44f28963df90dd5d232d7196f47d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.20.0 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch_lightning\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jSPOFSIqL2O0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c113d39d-6725-4857-8a06-d89e970e437b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "import zipfile\n",
        "\n",
        "# Mount Google Drive to access the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EZZkPwdpiZUM"
      },
      "outputs": [],
      "source": [
        "# Set the path to your zipped dataset\n",
        "zip_file_path = '/content/drive/MyDrive/M.Tech IITM/Deep Learning /aksharantar_sampled.zip'\n",
        "\n",
        "# Extract the dataset to a folder in Google Drive\n",
        "zip_ref = zipfile.ZipFile(zip_file_path, 'r')\n",
        "zip_ref.extractall('aksharantar_sampled_extracted')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sK3Uwyah0bEO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XHS4uGrK1Zjm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from google.colab import drive\n",
        "import csv\n",
        "\n",
        "\n",
        "# Path to your CSV file on Google Drive (Extracted file)\n",
        "csv_file_path = '/content/aksharantar_sampled_extracted/aksharantar_sampled/hin/hin_train.csv'\n",
        "\n",
        "# Read the CSV file and extract the sequence of characters\n",
        "with open(csv_file_path, 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    chars = []\n",
        "    for row in reader:\n",
        "        chars.extend(row[0])  # assuming the first column of the CSV file contains the text data\n",
        "\n",
        "charS=set(chars)\n",
        "charS.add('|')\n",
        "char_set = list(charS)\n",
        "\n",
        "\n",
        "# Define the mapping between characters and integer indices\n",
        "char_to_idx_latin= {char: i+1 for i, char in enumerate(char_set)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ItFlnDR47NaJ"
      },
      "outputs": [],
      "source": [
        "max_length_devanagari=0\n",
        "with open(csv_file_path, 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    chars = []\n",
        "\n",
        "    for row in reader:\n",
        "        chars.extend(row[1])  # assuming the first column of the CSV file contains the text data\n",
        "\n",
        "# Define the character set\n",
        "charS=set(chars)\n",
        "charS.add('|')\n",
        "char_set = list(charS)\n",
        "\n",
        "# Define the mapping between characters and integer indices\n",
        "char_to_idx_lang ={char: i+1 for i, char in enumerate(char_set)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "20RFt8fA4SFp"
      },
      "outputs": [],
      "source": [
        "max_length_latin = 0\n",
        "\n",
        "# Read the CSV file and extract the sequence of characters\n",
        "with open(csv_file_path, 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    chars = []\n",
        "\n",
        "    for row in reader:\n",
        "        length = len(row[0])  # assuming the column you want to check is the first one\n",
        "        if length > max_length_latin:\n",
        "            max_length_latin = length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7Yn_4Clu0mfs"
      },
      "outputs": [],
      "source": [
        "# max_length_latin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fV1YKBGW4-Sh"
      },
      "outputs": [],
      "source": [
        "max_length_devanagari = 0\n",
        "# Read the CSV file and extract the sequence of characters\n",
        "with open(csv_file_path, 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    chars = []\n",
        "\n",
        "    for row in reader:\n",
        "        length = len(row[1])  # assuming the column you want to check is the first one\n",
        "        if length > max_length_devanagari:\n",
        "            max_length_devanagari = length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yZWe8Duz1xOa"
      },
      "outputs": [],
      "source": [
        "# char_to_idx_lang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "l34YGvNz4meS"
      },
      "outputs": [],
      "source": [
        "# char_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uH15-PEi3ksM"
      },
      "outputs": [],
      "source": [
        "# char_to_idx_latin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sI7s-Oxt4ILm"
      },
      "outputs": [],
      "source": [
        "# max_length_devanagari"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4Mph9nZxUrO-"
      },
      "outputs": [],
      "source": [
        "def word_to_indices(word, max_length,dict):\n",
        "    # Convert the characters to integer indices using the char_to_idx mapping\n",
        "    indices = [dict.get(c, -1) for c in word]\n",
        "    # Filter out characters not in the dictionary\n",
        "    indices = [idx for idx in indices if idx >= 0]\n",
        "    # Add padding if necessary to make the sequence length equal to max_length\n",
        "    if len(indices) < max_length:\n",
        "        indices += [0] * (max_length - len(indices))\n",
        "    # Truncate the sequence if necessary to make the sequence length equal to max_length\n",
        "    elif len(indices) > max_length:\n",
        "        indices = indices[:max_length]\n",
        "    # Add the start and end tokens to the sequence\n",
        "    indices = [dict['|']] + indices + [dict['|']]\n",
        "    # Convert the list of indices to a tensor\n",
        "    tensor = torch.tensor(indices)\n",
        "    return tensor\n",
        "pairs=[]\n",
        "\n",
        "# Read the CSV file containing Latin-Devanagari word pairs\n",
        "with open('/content/aksharantar_sampled_extracted/aksharantar_sampled/hin/hin_train.csv', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for row in reader:\n",
        "        latin_word = row[0]\n",
        "        devanagari_word = row[1]\n",
        "        # Convert the Latin word to a tensor of integer indices\n",
        "        latin_indices = word_to_indices(latin_word, max_length_latin,char_to_idx_latin)\n",
        "        devanagari_indices= word_to_indices(devanagari_word,max_length_devanagari ,char_to_idx_lang)\n",
        "        pairs.append([latin_indices,devanagari_indices])\n",
        "        # print(devanagari_word, devanagari_indices)\n",
        "        # print(latin_word,latin_indices)\n",
        "        # print('**************************************************')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WE_BvvAbFzji"
      },
      "outputs": [],
      "source": [
        "# # len(train_dataloader[0])\n",
        "# for x,y in train_dataloader:\n",
        "#   print(x.shape,y.shape)\n",
        "#   break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "b14fgHBxO78M"
      },
      "outputs": [],
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(pairs, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "_K8umwAOWaCQ"
      },
      "outputs": [],
      "source": [
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
        "        self.rnn = nn.GRU(hidden_dim, hidden_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, hidden = self.rnn(embedded)\n",
        "        return hidden\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # print(\"Out embed\",hidden_dim)\n",
        "        self.embedding = nn.Embedding(hidden_dim, hidden_dim)\n",
        "        self.rnn = nn.GRU(hidden_dim, hidden_dim)\n",
        "        # print(\"Out Dime\",output_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # print(\"hidden\",hidden.shape)\n",
        "        # print(\"Bef x\",x.shape)\n",
        "        x = x.unsqueeze(0)\n",
        "        # print(\"Aft x\",x.shape)\n",
        "        embedded = self.embedding(x)\n",
        "        # print(\"embedded\",embedded.shape)\n",
        "        # print(\"hidden\",hidden.shape)\n",
        "        output, hidden = self.rnn(embedded, hidden)\n",
        "        prediction = self.fc(output.squeeze(0))\n",
        "        return prediction, hidden\n",
        "\n",
        "class Seq2Seq(pl.LightningModule):\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(input_dim, hidden_dim)\n",
        "        self.decoder = Decoder(output_dim, hidden_dim)\n",
        "        self.teacher_forcing_ratio = 0.5\n",
        "\n",
        "    def forward(self, src, trg):############################################Where r we calling this forward from\n",
        "        # print(\"Forward\")\n",
        "        # print(\"src\",src.shape,\"trg\",trg.shape)\n",
        "        batch_size = trg.shape[0]###################################################################\n",
        "        # print(\"src\",src.shape,\"trg\",trg.shape)\n",
        "        max_len = trg.shape[1]\n",
        "        # print(\"src\",src.shape,\"trg\",trg.shape)\n",
        "        trg_vocab_size = self.decoder.fc.out_features\n",
        "        # print(\"src\",src.shape,\"trg\",trg.shape)\n",
        "        src = src.transpose(0,1)\n",
        "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        hidden = self.encoder(src)\n",
        "        # print(\"trg\",trg.shape)\n",
        "        # input = trg[0,:]\n",
        "        input = trg[:,0]\n",
        "        # print(\"INP,Dec\",input.shape)\n",
        "        for t in range(1, max_len):\n",
        "            # print(\"t\",t,max_len,input.shape)\n",
        "            output, hidden = self.decoder(input, hidden)\n",
        "            # print(\"Out\",outputs.shape,output.shape)\n",
        "            outputs[t] = output\n",
        "            top1 = output.argmax(1)\n",
        "            input = top1 if self.teacher_forcing_ratio > torch.rand(1).item() else trg[:,t]\n",
        "        return outputs\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src, trg = batch\n",
        "        # print(\"Before forward trg\",trg.shape)\n",
        "        output = self(src, trg)\n",
        "        # print(\"After train output\",output.shape,\"trg\",trg.shape)\n",
        "        # After train output torch.Size([22, 64, 67]) trg torch.Size([64, 22])\n",
        "        # torch.Size([26, 2, 71]) torch.Size([2, 26])\n",
        "        \n",
        "#Ashok \n",
        "        # rows = np.arange(67)\n",
        "        # expected = torch.zeros(size=(output.shape))\n",
        "        # rows = np.arange(len(output))\n",
        "        # for f in range(len(trg)):\n",
        "        #     col = trg[f]\n",
        "        #     expected[rows,f,np.array(col.cpu())] = 1\n",
        "#\n",
        " \n",
        "#         \n",
        "        cols = torch.arange(output.shape[1]).unsqueeze(1)\n",
        "        rows = torch.arange(output.shape[0])\n",
        "        expected = torch.zeros(size=output.shape)\n",
        "        expected[rows, cols, trg.cpu()] = 1\n",
        "\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        expected = expected[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        loss = self.loss_fn(output, expected)\n",
        "        self.log('train_loss', loss)\n",
        "        return {'loss': loss}\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        # print(\"Validation\")\n",
        "        src, trg = batch\n",
        "        output = self(src, trg)\n",
        "        # print(\"Validation\",output.trg.shape)\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        loss = self.loss_fn(output, trg)\n",
        "        self.log('val_loss', loss)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters())\n",
        "        return optimizer\n",
        "\n",
        "    def loss_fn(self, output, trg):\n",
        "        # mask = (trg != self.pad_idx).float()\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        # print(\"Loss cal\",output.shape,trg.shape)\n",
        "        loss = criterion(output, trg)\n",
        "        # loss = criterion(output, trg) * mask\n",
        "        return loss.mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "bYNz4zlxHOmx"
      },
      "outputs": [],
      "source": [
        "model = Seq2Seq(len(char_to_idx_latin)+2, len(char_to_idx_lang)+2, 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Q6s3fsYjJWfC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309,
          "referenced_widgets": [
            "36c2a74535644fa084ea4248b9a4f6b8",
            "29e7d3bfdb3541cb993febd5d7e392a2",
            "5f6334aca4b545f6bb4008fb6b0f1a30",
            "ccdbbb61175e46f4a3048e84181e5460",
            "332e9f28d1a846dc80d19baa68238c4d",
            "c091a9f8c1c24dedbf182140051fa825",
            "ab7458de4bfb4f0e925b7c8b5569643e",
            "ab8765b5fa01401ebcf149645e6d999c",
            "81e8083986e54c8c94e069a44a4d702f",
            "ff9b721aebed41f6b82c80d198237559",
            "6ed818b698504d7fa38422768fc5951f"
          ]
        },
        "outputId": "f3daae59-fe2a-4586-d437-468946eb278d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name    | Type    | Params\n",
            "------------------------------------\n",
            "0 | encoder | Encoder | 402 K \n",
            "1 | decoder | Decoder | 477 K \n",
            "------------------------------------\n",
            "879 K     Trainable params\n",
            "0         Non-trainable params\n",
            "879 K     Total params\n",
            "3.519     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36c2a74535644fa084ea4248b9a4f6b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=1` reached.\n"
          ]
        }
      ],
      "source": [
        "trainer = pl.Trainer(max_epochs=1)\n",
        "# for x,y in train_dataloader:\n",
        "  # print(x.shape,y.shape)\n",
        "  # break\n",
        "trainer.fit(model, train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxSPKwTiPCbo"
      },
      "outputs": [],
      "source": [
        "  # max_length_latin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYgs-mD0U4sv"
      },
      "outputs": [],
      "source": [
        "# for x,y in train_dataloader:\n",
        "#   print(y)\n",
        "#   break"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "czgoKPmL3fnH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "36c2a74535644fa084ea4248b9a4f6b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29e7d3bfdb3541cb993febd5d7e392a2",
              "IPY_MODEL_5f6334aca4b545f6bb4008fb6b0f1a30",
              "IPY_MODEL_ccdbbb61175e46f4a3048e84181e5460"
            ],
            "layout": "IPY_MODEL_332e9f28d1a846dc80d19baa68238c4d"
          }
        },
        "29e7d3bfdb3541cb993febd5d7e392a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c091a9f8c1c24dedbf182140051fa825",
            "placeholder": "​",
            "style": "IPY_MODEL_ab7458de4bfb4f0e925b7c8b5569643e",
            "value": "Epoch 0: 100%"
          }
        },
        "5f6334aca4b545f6bb4008fb6b0f1a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab8765b5fa01401ebcf149645e6d999c",
            "max": 800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81e8083986e54c8c94e069a44a4d702f",
            "value": 800
          }
        },
        "ccdbbb61175e46f4a3048e84181e5460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff9b721aebed41f6b82c80d198237559",
            "placeholder": "​",
            "style": "IPY_MODEL_6ed818b698504d7fa38422768fc5951f",
            "value": " 800/800 [03:01&lt;00:00,  4.41it/s, v_num=4]"
          }
        },
        "332e9f28d1a846dc80d19baa68238c4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "c091a9f8c1c24dedbf182140051fa825": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab7458de4bfb4f0e925b7c8b5569643e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab8765b5fa01401ebcf149645e6d999c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81e8083986e54c8c94e069a44a4d702f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff9b721aebed41f6b82c80d198237559": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ed818b698504d7fa38422768fc5951f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}